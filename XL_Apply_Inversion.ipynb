{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"../../DATA/T2I.Models/stability-AI/stable-diffusion-xl-base-1.0/\"\n",
    "refiner_path=\"../../DATA/T2I.Models/stability-AI/stable-diffusion-xl-refiner-1.0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# mitigate CCUDA memory fragmentation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"max_split_size_mb:50\"\n",
    "!echo $PYTORCH_CUDA_ALLOC_CONF\n",
    "#turn Xformers OFF\n",
    "os.environ['FORCE_MEM_EFFICIENT_ATTN'] = \"1\"\n",
    "!echo $FORCE_MEM_EFFICIENT_ATTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline,DDIMScheduler,DDPMScheduler\n",
    "\n",
    "import torch\n",
    "from PIL import Image,ImageEnhance\n",
    "import torchvision.transforms as T\n",
    "from tqdm import auto\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for handling Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_XLembedding(emb,embedding_file=\"myToken.pt\",path=\"./Embeddings/\"):\n",
    "    torch.save(emb,path+embedding_file)\n",
    "\n",
    "def set_XLembedding(base,emb,token=\"my\"):\n",
    "    with torch.no_grad():            \n",
    "        # Embeddings[tokenNo] to learn\n",
    "        tokens=base.components[\"tokenizer\"].encode(token)\n",
    "        assert len(tokens)==3, \"token is not a single token in 'tokenizer'\"\n",
    "        tokenNo=tokens[1]\n",
    "        tokens=base.components[\"tokenizer_2\"].encode(token)\n",
    "        assert len(tokens)==3, \"token is not a single token in 'tokenizer_2'\"\n",
    "        tokenNo2=tokens[1]\n",
    "        embs=base.components[\"text_encoder\"].text_model.embeddings.token_embedding.weight\n",
    "        embs2=base.components[\"text_encoder_2\"].text_model.embeddings.token_embedding.weight\n",
    "        assert embs[tokenNo].shape==emb[\"emb\"].shape, \"different 'text_encoder'\"\n",
    "        assert embs2[tokenNo2].shape==emb[\"emb2\"].shape, \"different 'text_encoder_2'\"\n",
    "        embs[tokenNo]=emb[\"emb\"].to(embs.dtype).to(embs.device)\n",
    "        embs2[tokenNo2]=emb[\"emb2\"].to(embs2.dtype).to(embs2.device)\n",
    "\n",
    "def load_XLembedding(base,token=\"my\",embedding_file=\"myToken.pt\",path=\"./Embeddings/\"):\n",
    "    emb=torch.load(path+embedding_file)\n",
    "    set_XLembedding(base,emb,token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stable Diffusion XL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = DiffusionPipeline.from_pretrained(\n",
    "    base_path, \n",
    "    torch_dtype=torch.float16, #torch.bfloat16\n",
    "    variant=\"fp32\", \n",
    "    use_safetensors=True,\n",
    "    add_watermarker=False,\n",
    ")\n",
    "base.enable_xformers_memory_efficient_attention()\n",
    "torch.set_grad_enabled(False)\n",
    "_=base.to(\"cuda\")\n",
    "\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    refiner_path,\n",
    "    text_encoder_2=base.text_encoder_2,  \n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp32\",\n",
    "    use_safetensors=True,\n",
    "    add_watermarker=False,\n",
    ")\n",
    "refiner.enable_xformers_memory_efficient_attention()\n",
    "_=refiner.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learned=\"my\"\n",
    "embs_path=\"./Embeddings/\"\n",
    "emb_file=\"myPuppet768.pt\"\n",
    "\n",
    "load_XLembedding(base,token=learned,embedding_file=emb_file,path=embs_path)\n",
    "\n",
    "p1=\"The {} doll at the beach\"\n",
    "p2=\"The 3D rendering of a group of {} figurines dressed in red-striped bathing suits having fun at the beach\"\n",
    "p3=\"The 3D rendering of a group of {} figurines dressed in dirndl wearing sunglasses drinking beer and having fun at the oktoberfest\"\n",
    "negative_prompt=\"disfigure kitsch ugly oversaturated deformed mutation blurry mutated duplicate malformed cropped, bad anatomy, outof focus frame, poorly drawn face, low quality, cloned face, deformed face, squint eyes, malformed hand, fused fingers, crooked arm leg, missing disconnect arm leg\"\n",
    "n_steps=40\n",
    "high_noise_frac=.75\n",
    "\n",
    "for seed,sample_prompt in zip([20,30,40,1,8,9,45,75,90],[p1,p1,p1,p2,p2,p2,p3,p3,p3]): \n",
    "    prompt=sample_prompt.format(learned)\n",
    "    with torch.no_grad():    \n",
    "        torch.manual_seed(seed)\n",
    "        image = base(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=n_steps,\n",
    "            denoising_end=high_noise_frac,\n",
    "            output_type=\"latent\"\n",
    "        ).images\n",
    "\n",
    "        image = refiner(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=n_steps,\n",
    "            denoising_start=high_noise_frac,\n",
    "            image=image,\n",
    "        ).images[0]\n",
    "        display(image)\n",
    "        image.save(\"./Samples/{}.png\".format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
